{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compaire.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/Compairison_MI_GAN/blob/master/Compaire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Mvn1V30ejH",
        "colab_type": "code",
        "outputId": "8985c2c8-004a-453a-81b9-f67748f38aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import pandas as pd\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "from scipy import special\n",
        "#from Clustering_Equalgrps.equal_groups import EqualGroupsKMeans\n",
        "from tensorflow.keras import layers\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.7)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wlZswcMF7Rt",
        "colab_type": "text"
      },
      "source": [
        "#### Vergleich\n",
        "Als erstes für feste $k$ und $n$, was sich ändert ist die Samplesize, Anzahl der Samples und SNR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "ACHTUNG: CHANNELANZAHL WURDE UNTERSCHIEDLICH VERWENDET \\\\\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses\\\\\n",
        "$N$ - Länge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czeNNfpY1qc2",
        "colab": {}
      },
      "source": [
        "k = 4      # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 2    # Number of real channel uses per message\n",
        "#k = int(np.log2(M))\n",
        "#n = 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb-DiBwSN255",
        "colab_type": "text"
      },
      "source": [
        "### Different Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "\n",
        "EncIn = tf.keras.layers.Input(shape=(M,))#, dtype= tf.int32)\n",
        "e1 = tf.keras.layers.Dense(n, activation=None)\n",
        "e2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "EncOut = tf.keras.layers.Lambda(lambda x: x/tf.sqrt(2*tf.reduce_mean(tf.square(x))))\n",
        "GenIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "# = tf.keras.layers.Lambda(generator)\n",
        "DecIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "d1 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,n]))\n",
        "d2 = tf.keras.layers.Dense(M, activation='relu')\n",
        "DecOut = tf.keras.layers.Dense(M, activation='softmax')\n",
        "\n",
        "\n",
        "#noise_std = EbNo_to_noise(TRAINING_SNR)\n",
        "# custom functions / layers without weights\n",
        "norm_layer = keras.layers.Lambda(lambda x: tf.divide(x,tf.sqrt(2*tf.reduce_mean(tf.square(x)))))\n",
        "shape_layer = keras.layers.Lambda(lambda x: tf.reshape(x, shape=[-1,2,n]))\n",
        "shape_layer2 = keras.layers.Lambda(lambda x: tf.reshape(x, shape=[-1,2*n]))\n",
        "channel_layer = keras.layers.Lambda(lambda x: \n",
        "                    x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J96hJhKO9VJ",
        "colab_type": "text"
      },
      "source": [
        "### Help functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "def real_channel(x,noise_std):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "def B_Ber(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "def random_sample(batch_size=32):\n",
        "    msg = np.random.randint(M, size=batch_size)\n",
        "    return msg\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOoYuK_jR9rH",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxhmgOa0_7c",
        "colab_type": "text"
      },
      "source": [
        "#### Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator(n):\n",
        "  input1 = tf.keras.layers.Input(shape=(n,))\n",
        "  x1 = tf.keras.layers.Dense(n)(input1)\n",
        "  input2 =tf.random.normal([tf.shape(input1)[0],n])\n",
        "  x2 = tf.keras.layers.Dense(n)(input2)\n",
        "  subtracted = tf.keras.layers.Concatenate(1)([x1, x2])\n",
        "  h1 = tf.keras.layers.Dense(32,use_bias=True,  activation='relu')(subtracted)\n",
        "  h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "  out = tf.keras.layers.Dense(n, use_bias= True, activation='linear')(h2)\n",
        "  generator = tf.keras.models.Model(inputs=[input1], outputs=out)\n",
        "  return generator\n",
        "#keras.utils.plot_model(generator, 'Structure_of_MI_estimation.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt2rTP7hSFt4",
        "colab_type": "text"
      },
      "source": [
        "#### Discriminator Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_discriminator(n):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial,activation='relu',input_shape=((2*n,))))\n",
        "  #model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False, activation='sigmoid'))\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcIzLZj5Seh9",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNHtzAC4SPBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gan_encoder(M):\n",
        "  model = keras.models.Sequential([\n",
        "            keras.layers.Embedding(M, M, embeddings_initializer='glorot_normal'),\n",
        "            keras.layers.Dense(M, activation=\"elu\"),\n",
        "            keras.layers.Dense(n, activation=None),\n",
        "            e2,\n",
        "            EncOut,\n",
        "            GenIn])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5iCDE4dSL35",
        "colab_type": "text"
      },
      "source": [
        "#### decoder GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5KjEhDvSWQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gan_decoder(M):\n",
        "   model= keras.models.Sequential([\n",
        "                DecIn,\n",
        "                d1,\n",
        "                keras.layers.Dense(M, activation=\"elu\"),\n",
        "                keras.layers.Dense(M, activation=\"softmax\")\n",
        "                ])\n",
        "   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n15AvPFO05gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gan_optimizers(gen_learning_rate,disc_learning_rate):\n",
        "  generator_optimizer = tf.keras.optimizers.RMSprop(gen_learning_rate)      #RMSprop   in oreder to test where the error comes from\n",
        "  discriminator_optimizer = tf.keras.optimizers.RMSprop(disc_learning_rate) \n",
        "  return generator_optimizer, discriminator_optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(epochs,n_steps, batch_size, SNR_level):\n",
        "  noise_std = EbNo2Sigma(SNR_level)\n",
        "  start = time.time()\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32) \n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    counter += 1\n",
        "    train_step(noise_std, n_steps,batch_size)\n",
        "    if counter%100==0:\n",
        "      tf.print(\"counter %d:\" % (counter))\n",
        "      fake_c = generator(x)\n",
        "      tf.print(fake_c[0])\n",
        "    #print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "      tf.print ('Time for epoch {},'.format(epoch + 1))\n",
        "      \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WE_JS7kgA1W-",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(noise_std,n_steps,batch_size):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32) \n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  for i in range(n_steps):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_training_data = tf.concat(values=[real_channel(x,noise_std), x], axis=1)\n",
        "      fake_training_data = tf.concat(values=[generator(x),x], axis=1)\n",
        "      real_output = discriminator(real_training_data)\n",
        "      fake_output = discriminator(fake_training_data)\n",
        "      \n",
        "      \n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))\n",
        "      gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "      \n",
        "      #tf.print(disc_loss,gen_loss)\n",
        "      \n",
        "      if tf.math.is_nan(disc_loss) == False:\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n",
        "      if i == 4:  \n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "26f03141-bcf3-466c-8855-c6456d573fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "generator = get_generator(n)\n",
        "discriminator = get_discriminator(n)\n",
        "generator_optimizer, discriminator_optimizer = gan_optimizers(gen_learning_rate=0.0001, disc_learning_rate = 0.0001)\n",
        "train_gan(epochs  = 5000,n_steps=5, batch_size =100, SNR_level = 7)\n",
        "\n",
        "#4 after GAN training\n",
        "generator.trainable = False\n",
        "tf.print(generator.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counter 100:\n",
            "[0.0121279219 -0.0494267531]\n",
            "Time for epoch 100,\n",
            "counter 200:\n",
            "[-0.121408649 -0.0389147922]\n",
            "Time for epoch 200,\n",
            "counter 300:\n",
            "[-0.241952851 -0.070526056]\n",
            "Time for epoch 300,\n",
            "counter 400:\n",
            "[-0.346141577 -0.156223655]\n",
            "Time for epoch 400,\n",
            "counter 500:\n",
            "[-0.539972603 -0.219241977]\n",
            "Time for epoch 500,\n",
            "counter 600:\n",
            "[-0.254995763 0.74430567]\n",
            "Time for epoch 600,\n",
            "counter 700:\n",
            "[-0.339895785 0.389054477]\n",
            "Time for epoch 700,\n",
            "counter 800:\n",
            "[-1.41960311 -0.252035677]\n",
            "Time for epoch 800,\n",
            "counter 900:\n",
            "[-0.447045922 0.466530472]\n",
            "Time for epoch 900,\n",
            "counter 1000:\n",
            "[-1.20398593 0.139635935]\n",
            "Time for epoch 1000,\n",
            "counter 1100:\n",
            "[-0.81532 0.339143813]\n",
            "Time for epoch 1100,\n",
            "counter 1200:\n",
            "[-1.17339027 0.334751785]\n",
            "Time for epoch 1200,\n",
            "counter 1300:\n",
            "[-0.817172825 0.404820055]\n",
            "Time for epoch 1300,\n",
            "counter 1400:\n",
            "[-1.06087339 0.492287099]\n",
            "Time for epoch 1400,\n",
            "counter 1500:\n",
            "[-0.839089334 0.493828684]\n",
            "Time for epoch 1500,\n",
            "counter 1600:\n",
            "[-1.16196048 0.572092175]\n",
            "Time for epoch 1600,\n",
            "counter 1700:\n",
            "[-1.13100433 0.493261665]\n",
            "Time for epoch 1700,\n",
            "counter 1800:\n",
            "[-1.21427071 0.724244475]\n",
            "Time for epoch 1800,\n",
            "counter 1900:\n",
            "[-1.09711909 0.549728155]\n",
            "Time for epoch 1900,\n",
            "counter 2000:\n",
            "[-0.990649104 0.610300779]\n",
            "Time for epoch 2000,\n",
            "counter 2100:\n",
            "[-0.858449638 0.632998228]\n",
            "Time for epoch 2100,\n",
            "counter 2200:\n",
            "[-1.25310802 0.504584551]\n",
            "Time for epoch 2200,\n",
            "counter 2300:\n",
            "[-1.32035565 0.554591298]\n",
            "Time for epoch 2300,\n",
            "counter 2400:\n",
            "[-1.26911139 0.538090169]\n",
            "Time for epoch 2400,\n",
            "counter 2500:\n",
            "[-1.26843429 0.495455623]\n",
            "Time for epoch 2500,\n",
            "counter 2600:\n",
            "[-1.13089561 0.485275418]\n",
            "Time for epoch 2600,\n",
            "counter 2700:\n",
            "[-1.09737992 0.532675207]\n",
            "Time for epoch 2700,\n",
            "counter 2800:\n",
            "[-1.4259392 0.541460574]\n",
            "Time for epoch 2800,\n",
            "counter 2900:\n",
            "[-1.24032521 0.514385]\n",
            "Time for epoch 2900,\n",
            "counter 3000:\n",
            "[-1.18688965 0.548204541]\n",
            "Time for epoch 3000,\n",
            "counter 3100:\n",
            "[-1.1826297 0.559645]\n",
            "Time for epoch 3100,\n",
            "counter 3200:\n",
            "[-0.824365497 0.624378443]\n",
            "Time for epoch 3200,\n",
            "counter 3300:\n",
            "[-1.28423798 0.487368196]\n",
            "Time for epoch 3300,\n",
            "counter 3400:\n",
            "[-1.25394881 0.540905058]\n",
            "Time for epoch 3400,\n",
            "counter 3500:\n",
            "[-1.27754045 0.545501471]\n",
            "Time for epoch 3500,\n",
            "counter 3600:\n",
            "[-1.20436573 0.567488909]\n",
            "Time for epoch 3600,\n",
            "counter 3700:\n",
            "[-1.24476039 0.61654532]\n",
            "Time for epoch 3700,\n",
            "counter 3800:\n",
            "[-1.3180387 0.581241]\n",
            "Time for epoch 3800,\n",
            "counter 3900:\n",
            "[-1.42171788 0.620484829]\n",
            "Time for epoch 3900,\n",
            "counter 4000:\n",
            "[-1.39236403 0.402626097]\n",
            "Time for epoch 4000,\n",
            "counter 4100:\n",
            "[-1.29913986 0.751266241]\n",
            "Time for epoch 4100,\n",
            "counter 4200:\n",
            "[-1.28509438 0.615943611]\n",
            "Time for epoch 4200,\n",
            "counter 4300:\n",
            "[-1.12257397 0.647398829]\n",
            "Time for epoch 4300,\n",
            "counter 4400:\n",
            "[-1.01629055 0.260682732]\n",
            "Time for epoch 4400,\n",
            "counter 4500:\n",
            "[-1.08424819 0.522034168]\n",
            "Time for epoch 4500,\n",
            "counter 4600:\n",
            "[-1.24554181 0.619894505]\n",
            "Time for epoch 4600,\n",
            "counter 4700:\n",
            "[-1.29903567 0.63529551]\n",
            "Time for epoch 4700,\n",
            "counter 4800:\n",
            "[-1.2427268 0.597795546]\n",
            "Time for epoch 4800,\n",
            "counter 4900:\n",
            "[-1.38769162 0.618969381]\n",
            "Time for epoch 4900,\n",
            "counter 5000:\n",
            "[-1.26369262 0.751804471]\n",
            "Time for epoch 5000,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n",
            "Time for the training is 14.433379173278809 sec,\n",
            "False\n",
            "CPU times: user 20.7 s, sys: 516 ms, total: 21.2 s\n",
            "Wall time: 14.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GW2opX7SwMo",
        "colab_type": "text"
      },
      "source": [
        "# AE training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "b7d7f984-e5f0-4f50-90ad-a76496ba2dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "\n",
        "decoder = get_gan_decoder(M)\n",
        "encoder = get_gan_encoder(M)\n",
        "\n",
        "AE = tf.keras.models.Sequential([encoder,generator,decoder])\n",
        "\n",
        "\n",
        "data, test_data = random_sample(10000000), random_sample(10000)\n",
        "\n",
        "AE.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = AE.fit(data, data, batch_size=400,steps_per_epoch=200, epochs=10)\n",
        "\n",
        "#AE.summary()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000000 samples\n",
            "Epoch 1/10\n",
            "   76000/10000000 [..............................] - ETA: 5:56 - loss: 2.1353 - accuracy: 0.3414Epoch 2/10\n",
            "   77200/10000000 [..............................] - ETA: 1:33 - loss: 1.4738 - accuracy: 0.6447Epoch 3/10\n",
            "   79200/10000000 [..............................] - ETA: 1:31 - loss: 1.0845 - accuracy: 0.8392Epoch 4/10\n",
            "   76000/10000000 [..............................] - ETA: 1:28 - loss: 0.8058 - accuracy: 0.9293Epoch 5/10\n",
            "   78000/10000000 [..............................] - ETA: 1:26 - loss: 0.5932 - accuracy: 0.9668Epoch 6/10\n",
            "   75600/10000000 [..............................] - ETA: 1:30 - loss: 0.4460 - accuracy: 0.9733Epoch 7/10\n",
            "   74400/10000000 [..............................] - ETA: 1:29 - loss: 0.3431 - accuracy: 0.9813Epoch 8/10\n",
            "   78000/10000000 [..............................] - ETA: 1:25 - loss: 0.2672 - accuracy: 0.9861Epoch 9/10\n",
            "   76400/10000000 [..............................] - ETA: 1:28 - loss: 0.2158 - accuracy: 0.9888Epoch 10/10\n",
            "   78800/10000000 [..............................] - ETA: 1:31 - loss: 0.1752 - accuracy: 0.9911Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_2 (Sequential)    (None, None)              562       \n",
            "_________________________________________________________________\n",
            "model (Model)                (None, 2)                 1294      \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 16)                320       \n",
            "=================================================================\n",
            "Total params: 2,176\n",
            "Trainable params: 882\n",
            "Non-trainable params: 1,294\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "outputId": "a16d2205-96de-48f9-c24f-0614d7259a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "def test_encoding(M=16, n=1):\n",
        "    inp = np.arange(0,M)\n",
        "    coding = encoder.predict(inp)\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    plt.plot(coding[:,0], coding[:, 1], \"b.\")\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "    plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(-2, 2)\n",
        "    plt.gca().set_xlim(-2, 2)\n",
        "    plt.show()\n",
        "\n",
        "test_encoding(M,n)   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAEWCAYAAAAtl/EzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bsLeTCMKmfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}